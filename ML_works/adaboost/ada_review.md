
# Python + Numpyå®ç°adaboost

## å¯¼å…¥Numpy

    import numpy as np

## å®šä¹‰å¯¼å…¥æ•°æ®å‡½æ•°ï¼ˆ1.0ï¼‰

è‡ªå·±ç”Ÿæˆå°‘é‡æ•°æ®:  

    def loadSimpData():
        dataMatrix = np.matrix([[1., 2.1],
                                [2., 1.1],
                                [1.3, 1.],
                                [1., 1.],
                                [2., 1.]])
        classLabels = [1.0, 1.0, -1.0, -1.0, 1.0]
        return dataMatrix, classLabels

    dataMatrix, classLabels = loadSimpData()

## å®šä¹‰å¯¼å…¥æ•°æ®å‡½æ•°(2.0)

ç”¨è¿™æ®µç¨‹åºæ›¿æ¢ä¸Šä¸€èŠ‚  

ä»å’Œé²¸ç¤¾åŒºä¸Šä¸‹è½½æ•°æ®  

ä¸‹è½½åœ°å€ï¼š[ç”µç¦»å±‚æ•°æ®](https://www.kesci.com/home/dataset/5dc28bd6080dc30037200775)  

    filename = '/home/ylxiong/Documents/ionosphere.data'

    def loadDataSet(filename, begin=0, end=200):
        dataMatrix = []
        labelMatrix = []
        with open(filename) as fr:
            numFeat = len(fr.readline().split(','))
            for line in fr.readlines()[begin:end]:
                lineArr = []
                curLine = line.strip().split(',')
                for i in range(numFeat - 1):
                    lineArr.append(float(curLine[i]))
                dataMatrix.append(lineArr)
                # change the label into 1/-1
                # so the following calculation will be easier
                if curLine[-1] == 'g':
                    labelMatrix.append(1.0)
                else:
                    labelMatrix.append(-1.0)
        return dataMatrix, labelMatrix

## å®šä¹‰åˆ’åˆ†å•å…ƒ

ç»™å®šåˆ’åˆ†ç»´åº¦ã€é˜ˆå€¼ã€æ–¹å¼ï¼ˆå¤§äºé˜ˆå€¼/å°äºé˜ˆå€¼ï¼Ÿï¼‰  
å°†æ•°æ®é›†åˆ’åˆ†æˆ+1/-1ä¸¤è¾¹  
å°†åœ¨åç»­ä¸»å‡½æ•°ä¸­è°ƒç”¨è¿™ä¸ªå‡½æ•°  

    def stumpClassify(dataMatrix, dimension, threshVal, threshIneq):
        retArray = np.ones((np.shape(dataMatrix)[0], 1))
        # less than / greater than
        if threshIneq == 'lt':
            # dataMatrix[:, dimension] <= threshVal
            # means the certain index of [datas in
            # dataMatrix's x dimension that is smaller than threshVal]
            retArray[dataMatrix[:, dimension] <= threshVal] = -1.0
        else:
            retArray[dataMatrix[:, dimension] > threshVal] = -1.0
        return retArray

## å®šä¹‰å•ä¸ªåˆ’åˆ†ç»“ç‚¹

å¯¹äºç»™å®šæ•°æ®é›†ï¼Œæ‰¾å‡ºæœ€é€‚åˆçš„åˆ’åˆ†æ–¹å¼  

ä½•ä¸º[æœ€é€‚åˆ]ï¼Ÿ  
ç®—æ³•ä¹‹ä¸€ï¼š  
è¿ç”¨æ‰€æµ‹è¯•çš„æ–¹æ³•åˆ’åˆ†ï¼Œçœ‹åˆ†é”™äº†å¤šå°‘ä¸ªï¼Œå¯¹æ¯ä¸€ç¬”é”™è¯¯ä¹˜ä¸Šä¸€ä¸ªweightï¼Œé€‰å–æ€»å’Œæœ€å°çš„åˆ’åˆ†æ–¹å¼  

æ€ä¹ˆæ‰¾ï¼Ÿ  
éå†æ‰€æœ‰åˆ’åˆ†å¯èƒ½ï¼Œè®¡ç®—ä¸Šè¿°å€¼  

    ##### - build single decision tree - #####
    # D for weights
    # three loops
    # first: for all the features
    # second: for all the values
    # third: for > / <=

    def buildStump(dataArray, classLabels, D):
        dataMatrix = np.mat(dataArray)
        labelMatrix = np.mat(classLabels).T
        m, n = np.shape(dataMatrix)
        numSteps = 10.0
        bestStump = {}
        bestClasEst = np.mat(np.zeros((m, 1)))
        minError = np.inf
        for i in range(n):
            rangeMin = dataMatrix[:, i].min()
            rangeMax = dataMatrix[:, i].max()
            stepSize = (rangeMax - rangeMin)/numSteps
            for j in range(-1, int(numSteps)+1):
                for inequal in ['lt', 'gt']:
                    threshVal = (rangeMin + float(j)*stepSize)
                    predictedVals = stumpClassify(
                        dataMatrix, i, threshVal, inequal)
                    errArr = np.mat(np.ones((m, 1)))
                    errArr[predictedVals == labelMatrix] = 0
                    # D is the weights of each error
                    # errArr rf weather the model make a mistake in certain index
                    weightedError = np.dot(D.T, errArr)
                    print('split: dim % d, thresh: % .2f, inequal: % s,\
                        weightedError: %.3f' % (i, threshVal, inequal, weightedError))
                    if weightedError < minError:
                        minError = weightedError
                        bestClasEst = predictedVals.copy()
                        bestStump['dim'] = i
                        bestStump['thresh'] = threshVal
                        bestStump['ineq'] = inequal
        return bestStump, minError, bestClasEst

## å®šä¹‰ä¸»å‡½æ•°

é€’å½’åœ°ä½¿ç”¨ä¸Šè¿°å‡½æ•°è¿›è¡Œåˆ’åˆ†  
è¯¦è§æ³¨é‡Š  

    ##### - combine nodes together - #####
    # DS: decision stump, a weak classifier
    # not the only one, but the most popular one

    def adaBoostTrainDS(dataArray, classLabels, numIter=40):
        weakClassArr = []
        m = np.shape(dataArray)[0]
        D = np.mat(np.ones((m, 1))/m)
        aggClassEst = np.mat(np.zeros((m, 1)))
        # è®¾ç½®æœ€å¤§è¿­ä»£æ¬¡æ•°
        for i in range(numIter):
            # æ‰¾å‡ºå½“å‰æœ€å¥½çš„åˆ’åˆ†æ–¹æ¡ˆ
            bestStump, error, classEst = buildStump(
                dataArray, classLabels, D)
            print('D: ', D.T)
            # alphaå¯çœ‹ä½œå½“å‰åˆ’åˆ†å¯¹ç»“æœçš„ç½®ä¿¡åº¦ï¼Œåœ¨åé¢åŠ æƒè¦ç”¨
            alpha = float(0.5*np.log((1.0-error)/max(error, 1e-16)))# prvent 0 deviation
            bestStump['alpha'] = alpha
            weakClassArr.append(bestStump)
            print('classEst:', classEst.T)
            # é¢„æµ‹å’Œç»“æœç›¸åŒå¾—1åˆ†ï¼Œä¸åŒå¾—-1åˆ†ï¼Œä¹˜ä¸Š-alphaå–æŒ‡æ•°
            expon = np.multiply(-1*alpha*np.mat(classLabels).T, classEst)
            # å°†ä¸Šè¿°å€¼ä¹˜ä¸Šæƒé‡D
            D = np.multiply(D, np.exp(expon))
            # æ›´æ–°æƒé‡
            D = D/D.sum()
            # æ›´æ–°é¢„æµ‹
            aggClassEst += alpha*classEst
            print('aggClassEst:', aggClassEst.T)
            aggErrors = np.multiply(np.sign(aggClassEst) !=
                                    np.mat(classLabels).T, np.ones((m, 1)))
            # è®¡ç®—é”™è¯¯ç‡
            errorRate = aggErrors.sum()/m
            print('errorRate:', errorRate)
            # ä¸º0å°±ä¸ç”¨ç»§ç»­äº†
            if errorRate == 0:
                break
        return weakClassArr, aggClassEst

è‡³æ­¤æ¨¡å‹æ„å»ºå®Œæ¯•  

## å®šä¹‰åˆ†ç±»å‡½æ•°

æ ¹æ®é¢„æµ‹ç»“æœï¼Œæœ€åå¾—åˆ°å¤§äº0çš„ç»“æœå°±åˆ†ä¸ºæ­£ç±»  

    ### - classify - ###

    def adaClassify(datToClassify, classifierArr):
        dataMatrix = np.mat(datToClassify)
        m = np.shape(dataMatrix)[0]
        aggClassEst = np.mat(np.zeros((m, 1)))
        for i in range(len(classifierArr)):
            classEst = stumpClassify(dataMatrix, classifierArr[i]['dim'],
                                    classifierArr[i]['thresh'],
                                    classifierArr[i]['ineq'])
            aggClassEst += classifierArr[i]['alpha']*classEst
            print(aggClassEst)
        return np.sign(aggClassEst)

## å®šä¹‰ç»˜åˆ¶ROCæ›²çº¿

    def plotROC(predStrengths, classLabels):
        import matplotlib.pyplot as plt
        cur = [1.0, 1.0]
        ySum = 0.0
        # pos for positive
        numPosClass = sum(np.array(classLabels) == 1.0)
        yStep = 1/float(numPosClass)
        xStep = 1/float(len(classLabels)-numPosClass)
        sortedIndices = predStrengths.argsort()
        fig = plt.figure()
        fig.clf()
        ax = plt.subplot(111)
        for index in sortedIndices.tolist()[0]:
            if classLabels[index] == 1.0:
                delX = 0
                delY = yStep
            else:
                delX = xStep
                delY = 0
            ySum += cur[1]
            ax.plot([cur[0], cur[0]-delX], [cur[1], cur[1]-delY], c='b')
            cur = [cur[0]-delX, cur[1]-delY]
        ax.plot([0, 1], [0, 1], 'b--')
        plt.xlabel('False Positive')
        plt.ylabel('True Positive')
        plt.show()

## æ­£å¼å¼€å§‹

å®šä¹‰ç›¸å…³å‚æ•°

    numIter = 40
    begin = 230
    end = 250

å¯¼å…¥æ•°æ®

    dataMatrix, labelMatrix = loadDataSet(filename)
    testMatrix, testLabelMatrix = loadDataSet(filename, begin, end)

è®­ç»ƒæ¨¡å‹

    classifierArr, aggClassEst = adaBoostTrainDS(dataMatrix, labelMatrix, numIter)

é¢„æµ‹ç»“æœ

    prediction = adaClassify(testMatrix, classifierArr)
    errArr = np.mat(np.ones((end-begin, 1)))
    rate = errArr[prediction != np.mat(testLabelMatrix).T].sum()/(end - begin)
    print('testing error: ',rate*100,'%')

ç»˜åˆ¶ROC

    plotROC(aggClassEst.T, labelMatrix)

ç»“æœå¦‚ä¸‹ï¼š

![ROC plot](http://q5ioolwed.bkt.clouddn.com/ROC_mpl.png)

å°±æ˜¯è¿™æ ·äº†ğŸ˜‰
